use redlark_app::ai_service::{AIProvider, AIService};
use redlark_app::logger::Logger;
use redlark_app::types::AIModelConfig;
use std::env;

// åˆ›å»ºæµ‹è¯•ç”¨çš„ AI æä¾›å•†é…ç½®
fn create_test_provider() -> AIProvider {
    AIProvider {
        name: "test-provider".to_string(),
        base_url: "https://api.openai.com/v1".to_string(),
        api_key: env::var("OPENAI_API_KEY").unwrap_or("test-key".to_string()),
        default_model: "gpt-3.5-turbo".to_string(),
    }
}

// åˆ›å»ºæµ‹è¯•ç”¨çš„æ¨¡å‹é…ç½®
fn create_test_model_config() -> AIModelConfig {
    AIModelConfig {
        id: 1,
        name: "test-model".to_string(),
        model_id: "gpt-3.5-turbo".to_string(),
        display_name: "Test Model".to_string(),
        description: "Test model for unit testing".to_string(),
        max_tokens: Some(1000),
        temperature: Some(0.7),
        is_default: true,
        provider: redlark_app::types::AIProvider {
            id: 1,
            name: "test-provider".to_string(),
            display_name: "Test Provider".to_string(),
            base_url: "https://api.openai.com/v1".to_string(),
            api_key: env::var("OPENAI_API_KEY").unwrap_or("test-key".to_string()),
            description: "Test provider".to_string(),
            is_active: true,
            created_at: "2024-01-01T00:00:00Z".to_string(),
            updated_at: "2024-01-01T00:00:00Z".to_string(),
        },
    }
}

#[tokio::test]
async fn test_ai_service_creation() {
    let provider = create_test_provider();
    let service = AIService::new(provider.clone());

    // éªŒè¯æœåŠ¡åˆ›å»ºæˆåŠŸ
    assert_eq!(service.provider.name, provider.name);
    assert_eq!(service.provider.base_url, provider.base_url);
    println!("âœ… AI Service created successfully");
}

#[tokio::test]
async fn test_ai_service_from_model_config() {
    let model_config = create_test_model_config();
    let result = AIService::from_model_config(&model_config);

    assert!(result.is_ok());
    let service = result.unwrap();
    assert_eq!(service.provider.name, model_config.provider.name);
    assert_eq!(service.provider.base_url, model_config.provider.base_url);
    println!("âœ… AI Service created from model config successfully");
}

#[tokio::test]
async fn test_phonics_analysis_integration() {
    // åªæœ‰åœ¨æœ‰çœŸå® API å¯†é’¥æ—¶æ‰è¿è¡Œè¿™ä¸ªæµ‹è¯•
    if env::var("OPENAI_API_KEY").is_err() {
        println!("â­ï¸  Skipping integration test - no OPENAI_API_KEY found");
        return;
    }

    let model_config = create_test_model_config();
    let service = AIService::from_model_config(&model_config).unwrap();
    let logger = Logger::new();

    let test_text = "The cat sat on the mat.";

    println!("ğŸ”„ Testing phonics analysis with text: '{}'", test_text);

    // æµ‹è¯•è‡ªç„¶æ‹¼è¯»åˆ†æ
    let result = service
        .analyze_phonics(
            test_text,
            Some("gpt-3.5-turbo"),
            Some(500),
            Some(0.3),
            "focus",
            &logger,
        )
        .await;

    match result {
        Ok(analysis) => {
            println!("âœ… Phonics analysis successful!");
            println!(
                "ğŸ“Š Analysis result: {} words analyzed",
                analysis.words.len()
            );

            // éªŒè¯ç»“æœç»“æ„
            assert!(
                !analysis.words.is_empty(),
                "Should have analyzed some words"
            );

            // éªŒè¯æ¯ä¸ªå•è¯éƒ½æœ‰å¿…è¦çš„å­—æ®µ
            for word in &analysis.words {
                assert!(!word.word.is_empty(), "Word should not be empty");
                assert!(
                    !word.phonics_rule.is_empty(),
                    "Phonics rule should not be empty"
                );
                println!(
                    "ğŸ“ Word: {} | Rule: {} | IPA: {:?}",
                    word.word, word.phonics_rule, word.ipa_phonetic
                );
            }

            // éªŒè¯åˆ†æç»“æœçš„å®Œæ•´æ€§
            assert!(
                analysis.total_words > 0,
                "Total words should be greater than 0"
            );
            println!("ğŸ“ˆ Total words: {}", analysis.total_words);
            println!("ğŸ¯ Analysis successful - all assertions passed!");
        }
        Err(e) => {
            println!("âŒ Phonics analysis failed: {}", e);

            // åœ¨æµ‹è¯•ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬å¯èƒ½æœŸæœ›æŸäº›é”™è¯¯ï¼ˆå¦‚ç½‘ç»œé—®é¢˜ï¼‰
            let error_str = e.to_string().to_lowercase();
            let is_expected_error = error_str.contains("api")
                || error_str.contains("network")
                || error_str.contains("timeout")
                || error_str.contains("rate limit")
                || error_str.contains("unauthorized")
                || error_str.contains("invalid")
                || error_str.contains("connection");

            if is_expected_error {
                println!("âš ï¸  Expected error type (network/API related): {}", e);
            } else {
                panic!("Unexpected error type: {}", e);
            }
        }
    }
}

#[tokio::test]
async fn test_phonics_analysis_with_empty_text() {
    let model_config = create_test_model_config();
    let service = AIService::from_model_config(&model_config).unwrap();
    let logger = Logger::new();

    println!("ğŸ”„ Testing phonics analysis with empty text");

    let result = service
        .analyze_phonics(
            "",
            Some("gpt-3.5-turbo"),
            Some(500),
            Some(0.3),
            "focus",
            &logger,
        )
        .await;

    // ç©ºæ–‡æœ¬åº”è¯¥è¿”å›é”™è¯¯æˆ–ç©ºç»“æœ
    match result {
        Ok(analysis) => {
            println!("âœ… Empty text handled gracefully");
            assert!(
                analysis.words.is_empty(),
                "Empty text should result in no words"
            );
        }
        Err(e) => {
            println!("âœ… Empty text correctly returned error: {}", e);
            // ç©ºæ–‡æœ¬è¿”å›é”™è¯¯ä¹Ÿæ˜¯å¯ä»¥æ¥å—çš„
        }
    }
}

#[tokio::test]
async fn test_parameter_usage() {
    let model_config = create_test_model_config();

    // éªŒè¯é…ç½®å‚æ•°æ­£ç¡®è®¾ç½®
    assert_eq!(model_config.max_tokens, Some(1000));
    assert_eq!(model_config.temperature, Some(0.7));

    // éªŒè¯ç±»å‹è½¬æ¢
    let max_tokens_u32 = model_config.max_tokens.map(|t| t as u32);
    let temperature_f32 = model_config.temperature.map(|t| t as f32);

    assert_eq!(max_tokens_u32, Some(1000u32));
    assert_eq!(temperature_f32, Some(0.7f32));

    println!("âœ… Parameter usage test passed");
    println!(
        "ğŸ”§ max_tokens: {:?} -> {:?}",
        model_config.max_tokens, max_tokens_u32
    );
    println!(
        "ğŸ”§ temperature: {:?} -> {:?}",
        model_config.temperature, temperature_f32
    );
}

#[tokio::test]
async fn test_model_name_usage() {
    let model_config = create_test_model_config();
    let service = AIService::from_model_config(&model_config).unwrap();

    // éªŒè¯æ¨¡å‹åç§°æ­£ç¡®è®¾ç½®
    assert_eq!(model_config.model_id, "gpt-3.5-turbo");
    assert_eq!(service.provider.default_model, "gpt-3.5-turbo");

    println!("âœ… Model name usage test passed");
    println!("ğŸ·ï¸  Model ID: {}", model_config.model_id);
    println!("ğŸ·ï¸  Default model: {}", service.provider.default_model);
}

#[test]
fn test_prompt_template_loading() {
    // æµ‹è¯•æç¤ºè¯æ¨¡æ¿æ˜¯å¦èƒ½æ­£ç¡®åŠ è½½
    let prompt_template = include_str!("../src/prompts/agent.md");

    assert!(
        !prompt_template.is_empty(),
        "Prompt template should not be empty"
    );
    assert!(
        prompt_template.contains("è‡ªç„¶æ‹¼è¯»"),
        "Prompt should contain phonics-related content"
    );
    assert!(
        prompt_template.contains("XML"),
        "Prompt should mention XML format"
    );

    println!("âœ… Prompt template loaded successfully");
    println!("ğŸ“„ Template length: {} characters", prompt_template.len());
    println!(
        "ğŸ” Contains 'è‡ªç„¶æ‹¼è¯»': {}",
        prompt_template.contains("è‡ªç„¶æ‹¼è¯»")
    );
    println!("ğŸ” Contains 'XML': {}", prompt_template.contains("XML"));
}
